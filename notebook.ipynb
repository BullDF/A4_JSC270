{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BullDF/A4_JSC270/blob/Ethan/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrKKUxrAs0XD"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BullDF/A4_JSC270/blob/main/notebook.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BbZMtljs0XF"
      },
      "source": [
        "# JSC270 Assignment 4 by Johnny and Ethan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Rucah_-s0XF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88390f48-6023-44eb-eb15-8efc038b2004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "## Import necessary libraries\n",
        "from typing import List\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUt_PlDhs0XG"
      },
      "source": [
        "## Part I: Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPAEGWTos0XG"
      },
      "source": [
        "**a) Consider the training data. What is the balance between the three classes? In other words, what proportion of the observations (in the training set) belong to each class?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eGsSIvKBs0XH",
        "outputId": "fe3439eb-72df-4856-8119-8c6c166b1b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName   Location     TweetAt  \\\n",
              "0      3799       48751     London  16-03-2020   \n",
              "1      3800       48752         UK  16-03-2020   \n",
              "2      3801       48753  Vagabonds  16-03-2020   \n",
              "3      3802       48754        NaN  16-03-2020   \n",
              "4      3803       48755        NaN  16-03-2020   \n",
              "\n",
              "                                       OriginalTweet           Sentiment  \n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
              "1  advice Talk to your neighbours family to excha...            Positive  \n",
              "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
              "3  My food stock is not the only one which is emp...            Positive  \n",
              "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a373d3c-31eb-4803-bd67-70318580cbd0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a373d3c-31eb-4803-bd67-70318580cbd0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a373d3c-31eb-4803-bd67-70318580cbd0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a373d3c-31eb-4803-bd67-70318580cbd0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_url = 'https://raw.githubusercontent.com/3th4novo/JSC270_a4_dataset/main/Corona_NLP_train.csv'\n",
        "test_url = 'https://raw.githubusercontent.com/3th4novo/JSC270_a4_dataset/main/Corona_NLP_test.csv'\n",
        "\n",
        "df_train = pd.read_csv(train_url, encoding='latin-1')\n",
        "df_test = pd.read_csv(test_url, encoding='latin-1')\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "R8_MNwmls0XH",
        "outputId": "00689494-c707-4faf-dd91-c38f23b616fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive    0.438467\n",
              "Negative    0.374128\n",
              "Neutral     0.187404\n",
              "Name: Sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_train['Sentiment'].replace({'Extremely Negative': 'Negative', 'Extremely Positive': 'Positive'}, inplace=True)\n",
        "df_train['Sentiment'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIAiVmo0s0XI"
      },
      "source": [
        "**b) Tokenize the tweets. In other words, for each observation, convert the tweet from a single string of running text into a list of individual tokens (possibly with punctuation), splitting on whitespace. The result should be that each observation (tweet) is a list of individual tokens.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "D1RueAbSs0XI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8e4398-80e1-455d-ba66-c35ac3239ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    [@MeNyrbie, @Phil_Gahan, @Chrisitv, https://t....\n",
            "1    [advice, Talk, to, your, neighbours, family, t...\n",
            "2    [Coronavirus, Australia:, Woolworths, to, give...\n",
            "3    [My, food, stock, is, not, the, only, one, whi...\n",
            "4    [Me,, ready, to, go, at, supermarket, during, ...\n",
            "Name: tokens, dtype: object\n"
          ]
        }
      ],
      "source": [
        "def tokenize(tweet):\n",
        "   return tweet.split()\n",
        "\n",
        "df_train['tokens'] = df_train['OriginalTweet'].apply(tokenize)\n",
        "\n",
        "print(df_train['tokens'].head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ-0XdB7s0XI"
      },
      "source": [
        "**c) Using a regular expression, remove any URL tokens from each of the observations.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(lst):\n",
        "  result = [item for item in lst if not re.search('http\\S+|www\\.\\S+', item)]\n",
        "  return result\n",
        "\n",
        "df_train['tokens_no_url'] = df_train['tokens'].apply(remove_url)\n",
        "print(df_train['tokens_no_url'].head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjMWANAhiC8x",
        "outputId": "99ad7b74-d5b5-45f3-93b9-5c2aaa9c3e05"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        [@MeNyrbie, @Phil_Gahan, @Chrisitv, and, and]\n",
            "1    [advice, Talk, to, your, neighbours, family, t...\n",
            "2    [Coronavirus, Australia:, Woolworths, to, give...\n",
            "3    [My, food, stock, is, not, the, only, one, whi...\n",
            "4    [Me,, ready, to, go, at, supermarket, during, ...\n",
            "Name: tokens_no_url, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE7XjM2Xs0XI"
      },
      "source": [
        "**d) Remove all punctuation (,.?!;:’\") and special characters(@, #, +, &, =, $, etc). Also, convert all tokens to lowercase only. Can you think of a scenario when you might want to keep some forms of punctuation?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc_spec_lower(lst):\n",
        "    result = [re.sub('[^\\w\\s]', '', item) for item in lst]\n",
        "    lowered = [item.lower() for item in result]\n",
        "    return lowered\n",
        "\n",
        "df_train['tokens_no_punc'] = df_train['tokens_no_url'].apply(remove_punc_spec_lower)\n",
        "print(df_train['tokens_no_punc'].head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBNZKlGnjbHe",
        "outputId": "b692ae00-f908-4a50-c874-8b8f76c46b93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0           [menyrbie, phil_gahan, chrisitv, and, and]\n",
            "1    [advice, talk, to, your, neighbours, family, t...\n",
            "2    [coronavirus, australia, woolworths, to, give,...\n",
            "3    [my, food, stock, is, not, the, only, one, whi...\n",
            "4    [me, ready, to, go, at, supermarket, during, t...\n",
            "Name: tokens_no_punc, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPwFf6i6s0XI"
      },
      "source": [
        "**e) Now stem your tokens. This will have the effect of converting similar word forms into identical tokens (e.g. run, runs, running → run). Please specify which stemmer you use.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stemming(lst):\n",
        "  token_stems = [stemmer.stem(w) for w in lst]\n",
        "  return token_stems\n",
        "\n",
        "df_train['tokens_stemmed'] = df_train['tokens_no_punc'].apply(stemming)\n",
        "print(df_train['tokens_stemmed'].head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNWp4-2jkTNu",
        "outputId": "d7030f76-9435-4d62-a44f-6c543dc7c064"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0            [menyrbi, phil_gahan, chrisitv, and, and]\n",
            "1    [advic, talk, to, your, neighbour, famili, to,...\n",
            "2    [coronaviru, australia, woolworth, to, give, e...\n",
            "3    [my, food, stock, is, not, the, onli, one, whi...\n",
            "4    [me, readi, to, go, at, supermarket, dure, the...\n",
            "Name: tokens_stemmed, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rZnBRP9s0XJ"
      },
      "source": [
        "**f) Lastly, remove stopwords. Using the english stopwords list from nltk, remove these common words from your observations. This list is very long (I think almost 200 words), so remove only the first 100 stopwords in the list.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sw = stopwords.words('english')[0:100]\n",
        "\n",
        "def remove_sw(lst):\n",
        "  tokens_no_sw = [w for w in lst if w not in sw]\n",
        "  return tokens_no_sw\n",
        "\n",
        "df_train['stems_no_sw'] = df_train['tokens_stemmed'].apply(remove_sw)\n",
        "print(df_train['stems_no_sw'].head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBVGEv9jk7rz",
        "outputId": "6b2e3e0e-5b56-44ad-eb0b-20b068b8483d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                      [menyrbi, phil_gahan, chrisitv]\n",
            "1    [advic, talk, neighbour, famili, exchang, phon...\n",
            "2    [coronaviru, australia, woolworth, give, elder...\n",
            "3    [food, stock, not, onli, one, empti, pleas, do...\n",
            "4    [readi, go, supermarket, dure, covid19, outbre...\n",
            "Name: stems_no_sw, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aps0_7FYs0XJ"
      },
      "source": [
        "**g) Now convert your lists of words into vectors of word counts. You may find Scikit-learn’s CountVectorizer useful here. What is the length of your vocabulary?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate labels from features, converting to numpy arrays\n",
        "encode = {'Extremely Negative': 0, 'Negative': 0, 'Neutral': 1, 'Positive':2, 'Extremely Positive': 2}\n",
        "df_train['Sentiment_num'] = df_train['Sentiment'].map(encode)\n",
        "x_train, y_train = df_train['stems_no_sw'].to_numpy(), df_train['Sentiment_num'].to_numpy()\n",
        "\n",
        "def override_fcn(doc):\n",
        "  # We expect a list of tokens as input\n",
        "  return doc\n",
        "\n",
        "# Count Vectorizer\n",
        "count_vec = CountVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer= override_fcn,\n",
        "    preprocessor= override_fcn,\n",
        "    token_pattern= None,\n",
        "    max_features = 10000)\n",
        "\n",
        "counts_train = count_vec.fit_transform(x_train) # count matrix for the train data\n",
        "print(counts_train.toarray())"
      ],
      "metadata": {
        "id": "En-IIzxgnsz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a393ecf9-27a4-45f1-e128-e4f3d4f03e6b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I think this should be the size of volcabulary\n",
        "print(len(counts_train.toarray()[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXM2xZuw5wQW",
        "outputId": "65d79507-098d-4742-88fe-b45cbd7af5d3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEuNvpJZs0XJ"
      },
      "source": [
        "**h) Fit a Naive Bayes model to your data. Report the training and test error of the model. Use accuracy as the error metric. Also, report the 5 most probable words in each class, along with their counts. You might find Scikit-learn’s MultinomialNB() transformer useful. Use Laplace smoothing to prevent probabilities of zero.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DjKkDuLog2RD",
        "outputId": "d0b90477-e09e-4a5e-9692-fcabf4139381"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName             Location     TweetAt  \\\n",
              "0         1       44953                  NYC  02-03-2020   \n",
              "1         2       44954          Seattle, WA  02-03-2020   \n",
              "2         3       44955                  NaN  02-03-2020   \n",
              "3         4       44956          Chicagoland  02-03-2020   \n",
              "4         5       44957  Melbourne, Victoria  03-03-2020   \n",
              "\n",
              "                                       OriginalTweet           Sentiment  \n",
              "0  TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
              "1  When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
              "2  Find out how you can protect yourself and love...  Extremely Positive  \n",
              "3  #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
              "4  #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5272aa96-6946-446c-9aa7-c85bb6e70fc8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>44953</td>\n",
              "      <td>NYC</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44954</td>\n",
              "      <td>Seattle, WA</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>44955</td>\n",
              "      <td>NaN</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>Find out how you can protect yourself and love...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>44956</td>\n",
              "      <td>Chicagoland</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>44957</td>\n",
              "      <td>Melbourne, Victoria</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5272aa96-6946-446c-9aa7-c85bb6e70fc8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5272aa96-6946-446c-9aa7-c85bb6e70fc8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5272aa96-6946-446c-9aa7-c85bb6e70fc8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_test['Sentiment'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUZKDRaluP7-",
        "outputId": "10102bff-9cb3-436f-bf3b-a9e8d51c5827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Extremely Negative' 'Positive' 'Extremely Positive' 'Negative' 'Neutral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# repeat the vectorizing steps for test set\n",
        "df_test['tokens'] = df_test['OriginalTweet'].apply(tokenize)\n",
        "df_test['tokens_no_url'] = df_test['tokens'].apply(remove_url)\n",
        "df_test['tokens_no_punc'] = df_test['tokens_no_url'].apply(remove_punc_spec_lower)\n",
        "df_test['tokens_stemmed'] = df_test['tokens_no_punc'].apply(stemming)\n",
        "df_test['stems_no_sw'] = df_test['tokens_stemmed'].apply(remove_sw)\n",
        "df_test['Sentiment_num'] = df_test['Sentiment'].map(encode)\n",
        "x_test, y_test = df_test['stems_no_sw'].to_numpy(), df_test['Sentiment_num'].to_numpy()\n",
        "counts_test = count_vec.fit_transform(x_test) # This is the count matrix for the test data\n",
        "print(counts_test.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uRQ2-p2jfzy",
        "outputId": "a9ec98f4-48d3-49d9-b92d-3cf1ca30e669"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb = MultinomialNB(alpha=0.5) # alpha value larger than 1 -> smoother\n",
        "nb.fit(counts_train, y_train) \n",
        "\n",
        "test_preds = nb.predict(counts_test)\n",
        "\n",
        "print('Test accuracy with simple Naive Bayes:', accuracy_score(y_test, test_preds))"
      ],
      "metadata": {
        "id": "JrAw3Qc6iWDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0807c2-2813-413c-c2e9-6ea5aa693e01"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes: 0.22432859399684044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sofLx_Res0XJ"
      },
      "source": [
        "**i) Would it be appropriate to fit an ROC curve in this scenario? If yes, explain why. If no, explain why not.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJcLH8Mrs0XJ"
      },
      "source": [
        "**j) Redo parts G-H using TF-IDF vectors instead of count vectors. You might find Scikitlearn’s TfidfVectorizer() transformer useful. Report the training and test accuracy. How does this compare to the accuracy using count vectors?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TFIDF = TfidfTransformer()\n",
        "\n",
        "# use TFIDF transformer to transform both x matrices in train and test\n",
        "tfs_train = TFIDF.fit_transform(counts_train)\n",
        "tfs_test = TFIDF.fit_transform(counts_test)\n",
        "\n",
        "matrix_tftrain = tfs_train.toarray()\n",
        "print(len(matrix_tftrain[0]))\n",
        "\n",
        "nb1 = MultinomialNB(alpha=0.5)\n",
        "\n",
        "nb1.fit(tfs_train, y_train)\n",
        "\n",
        "tf_test_preds = nb1.predict(tfs_test)\n",
        "\n",
        "print('Test accuracy with simple Naive Bayes under TF-IDF:', accuracy_score(y_test, tf_test_preds))"
      ],
      "metadata": {
        "id": "cr7GZXkzjV7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c61af2-4e15-4c8f-bb72-7c5c66a08d26"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "Test accuracy with simple Naive Bayes under TF-IDF: 0.2783043707214323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7z1vqXs0XJ"
      },
      "source": [
        "**k) Recall lemmatization converts each word to its base form, which is a bit stronger than simply taking the stem. Redo parts E-H using TF-IDF vectors instead of count vectors. This time use lemmatization instead of stemming. Report train and test accuracy. How does the accuracy with lemmatization compare to the accuracy with stemming?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lem(lst):\n",
        "  return [lemmatizer.lemmatize(t) for t in lst]\n",
        "\n",
        "# process train data\n",
        "df_train['lem_tokens'] = df_train['tokens_no_punc'].apply(lem)\n",
        "df_train['lems_no_sw'] = df_train['lem_tokens'].apply(remove_sw)\n",
        "x_train_1, y_train_1 = df_train['lems_no_sw'].to_numpy(), df_train['Sentiment_num'].to_numpy()\n",
        "counts_train_1 = count_vec.fit_transform(x_train_1)\n",
        "tfs_train_1 = TFIDF.fit_transform(counts_train_1)"
      ],
      "metadata": {
        "id": "7x9iMRfTKX3F"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process test data\n",
        "df_test['lem_tokens'] = df_test['tokens_no_punc'].apply(lem)\n",
        "df_test['lems_no_sw'] = df_test['lem_tokens'].apply(remove_sw)\n",
        "x_test_1, y_test_1 = df_test['lems_no_sw'].to_numpy(), df_test['Sentiment_num'].to_numpy()\n",
        "counts_test_1 = count_vec.fit_transform(x_test_1)\n",
        "tfs_test_1 = TFIDF.fit_transform(counts_test_1)"
      ],
      "metadata": {
        "id": "0mXxbbDZxEvY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb2 = MultinomialNB(alpha=0.5)\n",
        "\n",
        "nb2.fit(tfs_train_1, y_train_1)\n",
        "\n",
        "tf_test_preds_1 = nb2.predict(tfs_test_1)\n",
        "\n",
        "print('Test accuracy with simple Naive Bayes under TF-IDF and lemmatization:', accuracy_score(y_test_1, tf_test_preds_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K50KieMyHZV",
        "outputId": "85c0bf1b-59ed-499a-f7da-6864a3b0ddc3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes under TF-IDF and lemmatization: 0.334913112164297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYEemL8-s0XJ"
      },
      "source": [
        "**Bonus: Is the Naive Bayes model generative or discriminative? Explain your response.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EY_wwjamfLOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 Having fun with NLP using the Twitter API"
      ],
      "metadata": {
        "id": "eIJb8XFxmDX6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xM9gRMXqmJI0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}